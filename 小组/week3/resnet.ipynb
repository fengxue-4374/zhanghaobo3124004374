{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f27218d-91d8-4d42-9ae0-a43391ba7141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU for training\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# 使用CPU\n",
    "device = torch.device(\"cpu\")\n",
    "print(\"Using CPU for training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65f12954-13c8-44b4-bffe-939e01e483ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义ResNet基本块\n",
    "class OptimizedBasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(OptimizedBasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != self.expansion * out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, self.expansion * out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = torch.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99e735dd-1b41-4221-a8bd-8d8d5ba9cf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义CPU优化的ResNet网络\n",
    "class CPUOptimizedResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(CPUOptimizedResNet, self).__init__()\n",
    "        self.in_channels = 32  # 减少初始通道数以降低计算量\n",
    "\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.layer1 = self._make_layer(block, 32, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 64, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 128, num_blocks[2], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.linear = nn.Linear(128 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbc6dee3-0f75-4990-a16c-4a8ef3c9c382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义可pickle的数据集类\n",
    "class CIFAR10Dataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8642a02f-1781-484d-8244-ae2da7a4e218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载CIFAR10数据\n",
    "def load_cifar10_cpu(data_dir):\n",
    "    # 训练数据\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    for i in range(1, 6):\n",
    "        batch_file = os.path.join(data_dir, f'data_batch_{i}')\n",
    "        with open(batch_file, 'rb') as fo:\n",
    "            batch_dict = pickle.load(fo, encoding='bytes')\n",
    "        train_data.append(batch_dict[b'data'])\n",
    "        train_labels += batch_dict[b'labels']\n",
    "\n",
    "    train_data = np.concatenate(train_data, dtype=np.uint8)\n",
    "    train_data = train_data.reshape((-1, 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "\n",
    "    # 测试数据\n",
    "    test_file = os.path.join(data_dir, 'test_batch')\n",
    "    with open(test_file, 'rb') as fo:\n",
    "        test_dict = pickle.load(fo, encoding='bytes')\n",
    "    test_data = test_dict[b'data']\n",
    "    test_labels = test_dict[b'labels']\n",
    "    test_data = np.array(test_data, dtype=np.uint8).reshape((-1, 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "\n",
    "    return train_data, train_labels, test_data, test_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba3b9af5-50fb-42fb-aae1-1afe4be5dc49",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (4013043470.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[11], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    train_transform = transforms.Compose([\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# CPU优化版获取数据转换\n",
    "def get_cpu_transforms():CPU优化版\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomHorizontalFlip(),  # 仅保留水平翻转，移除随机裁剪以减少计算\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "    return train_transform, test_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37c9e2d7-f4a0-4c0f-9c48-1b37886afcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU优化的训练函数\n",
    "def cpu_train_epoch(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_acc = 100. * correct / total\n",
    "\n",
    "    return train_loss, train_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e24a501a-216f-4460-89ed-d5b1caa40295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU优化的测试函数\n",
    "def cpu_test_epoch(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    test_loss = running_loss / len(test_loader)\n",
    "    test_acc = 100. * correct / total\n",
    "\n",
    "    return test_loss, test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9062fa2-bad3-4bd0-aa1a-730fe640280d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 主函数\n",
    "def main():\n",
    "    # 设置参数\n",
    "    data_dir = \"D:\\\\QG训练\\\\小组\\\\week3\"\n",
    "    batch_size = 64  # 减小批大小以适应CPU内存\n",
    "    initial_lr = 0.05  \n",
    "    num_epochs = 30  \n",
    "\n",
    "    # 加载数据\n",
    "    train_data, train_labels, test_data, test_labels = load_cifar10_cpu(data_dir)\n",
    "    train_transform, test_transform = get_cpu_transforms()\n",
    "\n",
    "    # 创建数据集\n",
    "    train_dataset = CIFAR10Dataset(train_data, train_labels, train_transform)\n",
    "    test_dataset = CIFAR10Dataset(test_data, test_labels, test_transform)\n",
    "\n",
    "    # 创建数据加载器(禁用多进程以在Windows上更好工作)\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True,\n",
    "        num_workers=0, pin_memory=False\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=batch_size, shuffle=False,\n",
    "        num_workers=0, pin_memory=False\n",
    "    )\n",
    "\n",
    "    # 初始化模型(更轻量级的版本)\n",
    "    model = CPUOptimizedResNet(OptimizedBasicBlock, [1, 1, 1]).to(device)  # 减少层数\n",
    "\n",
    "    # 使用交叉熵损失\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # 使用带动量的SGD优化器\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(),\n",
    "        lr=initial_lr,\n",
    "        momentum=0.9,\n",
    "        weight_decay=5e-4\n",
    "    )\n",
    "\n",
    "    # 使用简单的学习率衰减\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "    # 训练循环\n",
    "    best_acc = 0.0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start = time.time()\n",
    "\n",
    "        train_loss, train_acc = cpu_train_epoch(model, train_loader, criterion, optimizer)\n",
    "        test_loss, test_acc = cpu_test_epoch(model, test_loader, criterion)\n",
    "        scheduler.step()\n",
    "\n",
    "        epoch_time = time.time() - epoch_start\n",
    "\n",
    "        # 保存最佳模型\n",
    "        if test_acc > best_acc:\n",
    "            best_acc = test_acc\n",
    "            torch.save(model.state_dict(), 'best_model_cpu.pth')\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}] | '\n",
    "              f'Time: {epoch_time:.2f}s | '\n",
    "              f'Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | '\n",
    "              f'Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.2f}% | '\n",
    "              f'Best Acc: {best_acc:.2f}%')\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f'Training completed in {total_time:.2f} seconds')\n",
    "    print(f'Best Test Accuracy: {best_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e079bf5-2b5c-43d7-bdcf-66ccb0eaf371",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02240454-bd56-4204-bd50-5461da6808cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
